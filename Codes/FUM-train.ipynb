{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lantrungseo/FUM-code/blob/main/Codes/FUM-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "qNAecU6e9_-s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w-ypHpX2qpNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07238714-29d2-482e-bf88-2d75ea58a8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ayvQaeBNrT9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c065c610-79bb-4fc7-ac08-56232713ece2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MINDlarge_dev  MINDlarge_test  MINDlarge_train\tMINDsmall_dev  MINDsmall_train\n",
            "glove.840B.300d.txt\n",
            "Generator.py  Hypers.py  Models.py  Preprocessing.py  Utils.py\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/gdrive/MyDrive/Dataset/MIND/_data_'\n",
        "!ls '/content/gdrive/MyDrive/Dataset/MIND/_embeddings_/'\n",
        "!ls '/content/gdrive/MyDrive/Projects/MIND-FUM'\n",
        "\n",
        "!rsync -a '/content/gdrive/MyDrive/Projects/MIND-FUM/' ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aZI83SfstNJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1226c38e-93cb-49eb-b51b-a5b6c0fb3825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tGenerator.py  Hypers.py  Models.py  Preprocessing.py  sample_data  Utils.py\n"
          ]
        }
      ],
      "source": [
        "!ls ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdoP0GCUtWZW",
        "outputId": "67c62ba1-b65c-449c-bc83-7fab30ca7fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Dataset/MIND/_data_\n",
            "/content/gdrive/MyDrive/Dataset/MIND/_embeddings_\n"
          ]
        }
      ],
      "source": [
        "from Hypers import *\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from Generator import *\n",
        "from Models import *\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "project_path = '/content/gdrive/MyDrive/Dataset/MIND/'\n",
        "data_root_path = os.path.join(project_path, '_data_')\n",
        "embedding_path = os.path.join(project_path, '_embeddings_')\n",
        "\n",
        "print(data_root_path)\n",
        "print(embedding_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbgaiulgyZSE",
        "outputId": "6ec7150f-7e31-480c-f46b-352c7ee113a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.17.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk tensorflow dask pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2iKkQK1yr_L",
        "outputId": "2d8d66f3-8bc1-46a8-f51c-e69ef2759d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# download punkt data for nltk\n",
        "import nltk\n",
        "# nltk_data_dir_path = os.path.join(project_path, '_nltk_data_')\n",
        "# os.environ['NLTK_DATA'] = nltk_data_dir_path\n",
        "nltk.download('punkt')#, download_dir=nltk_data_dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydKD8WV6yyTP",
        "outputId": "a0297246-a7ec-4718-d64a-4d0a6eb56b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Dataset/MIND/_data_\n",
            "MINDlarge_train\n",
            "MINDlarge_test\n",
            "MINDlarge_dev\n",
            "MINDsmall_train\n",
            "MINDsmall_dev\n"
          ]
        }
      ],
      "source": [
        "print(data_root_path)\n",
        "news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict = read_news(\n",
        "  data_root_path,\n",
        ")\n",
        "\n",
        "\n",
        "news_title,news_vert,news_subvert,news_entity,news_content=get_doc_input(news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vdQsiBnzy4In"
      },
      "outputs": [],
      "source": [
        "title_word_embedding_matrix = load_matrix(embedding_path,word_dict)\n",
        "content_word_embedding_matrix = load_matrix(embedding_path,content_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PwLCWgcJy6ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f642bceb-4c73-4881-eb98-6b0950abded1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'N88753': ['lifestyle', 'lifestyleroyals', ['the', 'brands', 'queen', 'elizabeth', ',', 'prince', 'charles', ',', 'and', 'prince', 'philip', 'swear', 'by'], ['Q80976', 'Q43274', 'Q9682'], ['shop', 'the', 'notebooks,', 'jackets,', 'and', 'more', 'that', 'the', 'royals', \"can't\", 'live', 'without.']], 'N45436': ['news', 'newsscienceandtechnology', ['walmart', 'slashes', 'prices', 'on', 'last-generation', 'ipads'], ['Q2796', 'Q483551'], [\"apple's\", 'new', 'ipad', 'releases', 'bring', 'big', 'deals', 'on', 'last', \"year's\", 'models.']], 'N23144': ['health', 'weightloss', ['50', 'worst', 'habits', 'for', 'belly', 'fat'], ['Q193583'], ['these', 'seemingly', 'harmless', 'habits', 'are', 'holding', 'you', 'back', 'and', 'keeping', 'you', 'from', 'shedding', 'that', 'unwanted', 'belly', 'fat', 'for', 'good.']], 'N86255': ['health', 'medical', ['dispose', 'of', 'unwanted', 'prescription', 'drugs', 'during', 'the', 'dea', \"'s\", 'take', 'back', 'day'], ['Q622899'], []]}\n",
            "{'N88753': 1, 'N45436': 2, 'N23144': 3, 'N86255': 4}\n",
            "{'lifestyle': 1, 'news': 2, 'health': 3, 'sports': 4}\n",
            "{'lifestyleroyals': 1, 'newsscienceandtechnology': 2, 'weightloss': 3, 'medical': 4}\n",
            "58218\n",
            "54184\n",
            "(130380, 30)\n",
            "(130380, 50)\n",
            "(58219, 300)\n",
            "(54185, 300)\n"
          ]
        }
      ],
      "source": [
        "def print_partial(d):\n",
        "  print(dict(list(d.items())[0:4]))\n",
        "\n",
        "print_partial(news)\n",
        "print_partial(news_index)\n",
        "print_partial(category_dict)\n",
        "print_partial(subcategory_dict)\n",
        "\n",
        "print(len(word_dict))\n",
        "print(len(content_dict))\n",
        "\n",
        "print(news_title.shape)\n",
        "print(news_content.shape)\n",
        "\n",
        "print(title_word_embedding_matrix.shape)\n",
        "print(content_word_embedding_matrix.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_session = read_train_clickhistory(news_index,data_root_path,'MINDlarge_train/behaviors.tsv')\n",
        "dev_session = read_train_clickhistory(news_index,data_root_path,'MINDlarge_dev/behaviors.tsv')\n",
        "\n",
        "train_user = parse_user(news_index,train_session)\n",
        "dev_user = parse_user(news_index,dev_session)\n",
        "\n",
        "train_sess, train_user_id, train_label = get_train_input(news_index,train_session)\n",
        "dev_sess, dev_user_id, dev_label = get_train_input(news_index,dev_session)"
      ],
      "metadata": {
        "id": "tMponzcoSeli"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H6IbtWLhy-ra"
      },
      "outputs": [],
      "source": [
        "# # Save preprocessing data as csv\n",
        "# import pandas as pd\n",
        "# import json\n",
        "\n",
        "# def get_paths(folder):\n",
        "#   train_session_path = os.path.join(project_path, '_data_', folder, 'train_session.csv')\n",
        "#   train_user_path = os.path.join(project_path, '_data_', folder, 'train_user_id.csv')\n",
        "#   train_label_path = os.path.join(project_path, '_data_', folder,  'train_label.csv')\n",
        "#   train_click_path = os.path.join(project_path, '_data_',folder,  'train_clicks.csv')\n",
        "#   train_meta_path = os.path.join(project_path, '_data_', folder, 'train-meta.json')\n",
        "\n",
        "#   dev_session_path = os.path.join(project_path, '_data_', folder, 'dev_session.csv')\n",
        "#   dev_user_path = os.path.join(project_path, '_data_', folder, 'dev_user_id.csv')\n",
        "#   dev_label_path = os.path.join(project_path, '_data_', folder, 'dev_label.csv')\n",
        "#   dev_click_path = os.path.join(project_path, '_data_', folder, 'dev_clicks.csv')\n",
        "#   dev_meta_path = os.path.join(project_path, '_data_', folder, 'dev-meta.json')\n",
        "#   return train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path\n",
        "\n",
        "# def save_processed_data_as_csv(folder):\n",
        "#   train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path = get_paths(folder)\n",
        "\n",
        "#   train_sess_df = pd.DataFrame(train_sess)\n",
        "#   train_sess_df.to_csv(train_session_path, index=False,header=False)\n",
        "\n",
        "#   train_user_id_df = pd.DataFrame(train_user_id)\n",
        "#   train_user_id_df.to_csv(train_user_path, index=False,header=False)\n",
        "\n",
        "#   train_label_df = pd.DataFrame(train_label)\n",
        "#   train_label_df.to_csv(train_label_path, index=False,header=False)\n",
        "\n",
        "#   dev_sess_df = pd.DataFrame(dev_sess)\n",
        "#   dev_sess_df.to_csv(dev_session_path, index=False,header=False)\n",
        "\n",
        "#   dev_user_id_df = pd.DataFrame(dev_user_id)\n",
        "#   dev_user_id_df.to_csv(dev_user_path, index=False,header=False)\n",
        "\n",
        "#   dev_label_df = pd.DataFrame(dev_label)\n",
        "#   dev_label_df.to_csv(dev_label_path, index=False,header=False)\n",
        "\n",
        "#   train_click_df = pd.DataFrame(train_user['click'][train_user_id])\n",
        "#   train_click_df.to_csv(train_click_path, index=False,header=False)\n",
        "\n",
        "#   dev_click_df = pd.DataFrame(dev_user['click'][dev_user_id])\n",
        "#   dev_click_df.to_csv(dev_click_path, index=False,header=False)\n",
        "\n",
        "\n",
        "#   with open(train_meta_path, 'w') as f:\n",
        "#     json.dump({ \"impressionNum\": train_label.shape[0] }, f)\n",
        "\n",
        "#   with open(dev_meta_path, 'w') as f:\n",
        "#     json.dump({ \"impressionNum\": dev_label.shape[0] }, f)\n",
        "\n",
        "#   # return train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path\n",
        "# train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path = get_paths('_small-processed_')\n",
        "# # save_processed_data_as_csv('_small-processed_')\n",
        "# # save_processed_data_as_csv('_processed_')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F5lX0VHbzHb5"
      },
      "outputs": [],
      "source": [
        "from Generator import NewsFetcher\n",
        "news_fetcher = NewsFetcher(news_title,news_content,news_vert,news_subvert,news_entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-DP2x4bqzIUU"
      },
      "outputs": [],
      "source": [
        "train_generator = get_train_generator_2(news_fetcher,train_user['click'],train_user_id,train_sess,train_label,64)\n",
        "val_generator = get_train_generator_2(news_fetcher,dev_user['click'], dev_user_id, dev_sess, dev_label, 64)\n",
        "news_generator = get_hir_news_generator(news_fetcher,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZyIRNjBLzMGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337cdc22-ccc2-411d-dfc2-cd04982dca7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52870\n",
            "8982\n",
            "(64, 5, 87) (64, 30, 87) (64, 5)\n"
          ]
        }
      ],
      "source": [
        "print(len(train_generator))\n",
        "print(len(val_generator))\n",
        "# print(train_generator.label_reader.loc[100:120].compute().values)\n",
        "\n",
        "res = val_generator[2000]\n",
        "\n",
        "print(res[0][0].shape, res[0][1].shape, res[1].shape)\n",
        "\n",
        "# train_generator[i] return i-th batch with format ((news_info, user_info), [labels])\n",
        "\n",
        "# news_info.shape = (batch_size, train_sess.shape[1]=npratio+1, 87) -> represent the current clicked news and 4 not-clicked news\n",
        "# user_info.shape = (batch_size, 50, 87) -> represent the clicked news before the current clicked news\n",
        "# labels.shape = (batch_size, 5) -> 1 for clicked news, 0 for not-clicked news matched with news_info -> (1, 0, 0, 0, 0)\n",
        "\n",
        "# test code\n",
        "# gen_news_data, gen_labels = train_generator[0]\n",
        "# gen_news_info, gen_user_info = gen_news_data\n",
        "\n",
        "# print(gen_news_info.shape)\n",
        "# print(gen_user_info.shape)\n",
        "# print(gen_labels[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uhYFSoTyzOcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37761616-9d98-410b-e5ac-950d70a28fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)       [(None, 30, 87)]             0         []                            \n",
            "                                                                                                  \n",
            " input_15 (InputLayer)       [(None, 5, 87)]              0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 30, 400)              4365399   ['input_14[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDi  (None, 5, 400)               4365399   ['input_15[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " model_8 (Functional)        (None, 370)                  708771    ['time_distributed_1[0][0]']  \n",
            "                                                                                                  \n",
            " model_12 (Functional)       (None, 30)                   1769519   ['input_14[0][0]']            \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 5, 400)               0         ['time_distributed_2[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 400)                  0         ['model_8[0][0]',             \n",
            " )                                                                   'model_12[0][0]']            \n",
            "                                                                                                  \n",
            " dot_6 (Dot)                 (None, 5)                    0         ['dropout_19[0][0]',          \n",
            "                                                                     'concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " recommend (Activation)      (None, 5)                    0         ['dot_6[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62057954 (236.73 MB)\n",
            "Trainable params: 62057954 (236.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "news_encoder\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 87)]                 0         []                            \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 1)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 1)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 1, 128)               2432      ['lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)     (None, 1, 128)               37632     ['lambda_2[0][0]']            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 128)                  0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 128)                  0         ['embedding_4[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 30)                   0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)           (None, 50)                   0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  16512     ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  16512     ['reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)           (None, 5)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, 400)                  1790610   ['lambda[0][0]']              \n",
            "                                                          1                                       \n",
            "                                                                                                  \n",
            " model_3 (Functional)        (None, 400)                  1669590   ['lambda_3[0][0]']            \n",
            "                                                          1                                       \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 128)                  0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 128)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " model_5 (Functional)        (None, 200)                  8476101   ['lambda_4[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1256)                 0         ['model_1[0][0]',             \n",
            "                                                                     'model_3[0][0]',             \n",
            "                                                                     'dropout_9[0][0]',           \n",
            "                                                                     'dropout_10[0][0]',          \n",
            "                                                                     'model_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 400)                  502800    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43653991 (166.53 MB)\n",
            "Trainable params: 43653991 (166.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "user_encoder\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)       [(None, 30, 87)]             0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 30, 400)              4365399   ['input_14[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " model_8 (Functional)        (None, 370)                  708771    ['time_distributed_1[0][0]']  \n",
            "                                                                                                  \n",
            " model_12 (Functional)       (None, 30)                   1769519   ['input_14[0][0]']            \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 400)                  0         ['model_8[0][0]',             \n",
            " )                                                                   'model_12[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62057954 (236.73 MB)\n",
            "Trainable params: 62057954 (236.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "model,news_encoder,user_encoder, = create_model(title_word_embedding_matrix,content_word_embedding_matrix,entity_dict,category_dict,subcategory_dict)\n",
        "\n",
        "print(\"model\")\n",
        "model.summary()\n",
        "print(\"news_encoder\")\n",
        "news_encoder.summary()\n",
        "print(\"user_encoder\")\n",
        "user_encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vrMDZEQ1zwCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ce74ab-6dd7-4a04-e71a-dcda0ddc65ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load weights from /content/gdrive/MyDrive/Dataset/MIND/_checkpoints_/cp.ckpt\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_dir = os.path.join(project_path, '_checkpoints_')\n",
        "checkpoint_path = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "latest_weight = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "if latest_weight:\n",
        "    model.load_weights(latest_weight)\n",
        "    print(\"load weights from {}\".format(latest_weight))\n",
        "else:\n",
        "    print(\"no weights found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback =keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "model.fit_generator(train_generator,epochs=3, verbose=True, validation_data=val_generator, callbacks=[cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "EDANKqB3AocJ",
        "outputId": "0c5c4efb-4cdb-4e53-853e-b68e1b6130b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-1cabea32117d>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator,epochs=3, verbose=True, validation_data=val_generator, callbacks=[cp_callback])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52870/52870 [==============================] - ETA: 0s - loss: 1.3028 - acc: 0.5129\n",
            "Epoch 1: saving model to /content/gdrive/MyDrive/Dataset/MIND/_checkpoints_/cp.ckpt\n",
            "52870/52870 [==============================] - 7770s 147ms/step - loss: 1.3028 - acc: 0.5129 - val_loss: 1.4233 - val_acc: 0.4247\n",
            "Epoch 2/3\n",
            "   80/52870 [..............................] - ETA: 2:03:02 - loss: 1.2893 - acc: 0.5139"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1cabea32117d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  verbose=1)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2911\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m         )\n\u001b[0;32m-> 2913\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2914\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0aaTMJTZz_uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(project_path, '_models_/model_small.keras')\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "id": "uUhKNG3H63XA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPnc2Ytl35/8VrtyryOJjIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}