{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lantrungseo/FUM-code/blob/main/Codes/FUM_code_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "qNAecU6e9_-s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w-ypHpX2qpNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973db102-1f67-4549-cefd-4f5ada66b09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ayvQaeBNrT9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e0317f-99e3-4a95-d412-ac32c00c93bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MINDlarge_dev  MINDlarge_test  MINDlarge_train\tMINDsmall_dev  MINDsmall_train\n",
            "glove.840B.300d.txt\n",
            "Generator.py  Hypers.py  Models.py  Preprocessing.py  Utils.py\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/gdrive/MyDrive/Dataset/MIND/_data_'\n",
        "!ls '/content/gdrive/MyDrive/Dataset/MIND/_embeddings_/'\n",
        "!ls '/content/gdrive/MyDrive/Projects/MIND-FUM'\n",
        "\n",
        "!rsync -a '/content/gdrive/MyDrive/Projects/MIND-FUM/' ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aZI83SfstNJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcd3445-58da-4ba2-9022-5a89893b8823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tGenerator.py  Hypers.py  Models.py  Preprocessing.py  sample_data  Utils.py\n"
          ]
        }
      ],
      "source": [
        "!ls ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdoP0GCUtWZW",
        "outputId": "204324a1-c2f4-4616-af22-fdb391bf4926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Dataset/MIND/_data_\n",
            "/content/gdrive/MyDrive/Dataset/MIND/_embeddings_\n"
          ]
        }
      ],
      "source": [
        "from Hypers import *\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from Generator import *\n",
        "from Models import *\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "project_path = '/content/gdrive/MyDrive/Dataset/MIND/'\n",
        "data_root_path = os.path.join(project_path, '_data_')\n",
        "embedding_path = os.path.join(project_path, '_embeddings_')\n",
        "\n",
        "print(data_root_path)\n",
        "print(embedding_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbgaiulgyZSE",
        "outputId": "90506607-7803-44f5-91e3-e978083bd5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.17.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk tensorflow dask pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2iKkQK1yr_L",
        "outputId": "1328bb33-5451-4b58-9592-ada522ab9504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# download punkt data for nltk\n",
        "import nltk\n",
        "# nltk_data_dir_path = os.path.join(project_path, '_nltk_data_')\n",
        "# os.environ['NLTK_DATA'] = nltk_data_dir_path\n",
        "nltk.download('punkt')#, download_dir=nltk_data_dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydKD8WV6yyTP",
        "outputId": "2d7450a0-6046-4db4-9e81-638a49b0776a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Dataset/MIND/_data_\n",
            "MINDlarge_train\n",
            "MINDlarge_test\n",
            "MINDlarge_dev\n",
            "MINDsmall_train\n",
            "MINDsmall_dev\n"
          ]
        }
      ],
      "source": [
        "print(data_root_path)\n",
        "news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict = read_news(\n",
        "  data_root_path,\n",
        ")\n",
        "\n",
        "\n",
        "news_title,news_vert,news_subvert,news_entity,news_content=get_doc_input(news,news_index,category_dict,subcategory_dict,word_dict,content_dict,entity_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vdQsiBnzy4In"
      },
      "outputs": [],
      "source": [
        "title_word_embedding_matrix = load_matrix(embedding_path,word_dict)\n",
        "content_word_embedding_matrix = load_matrix(embedding_path,content_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PwLCWgcJy6ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde39037-3186-46cc-f36d-4ba72af843ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'N88753': ['lifestyle', 'lifestyleroyals', ['the', 'brands', 'queen', 'elizabeth', ',', 'prince', 'charles', ',', 'and', 'prince', 'philip', 'swear', 'by'], ['Q80976', 'Q43274', 'Q9682'], ['shop', 'the', 'notebooks,', 'jackets,', 'and', 'more', 'that', 'the', 'royals', \"can't\", 'live', 'without.']], 'N45436': ['news', 'newsscienceandtechnology', ['walmart', 'slashes', 'prices', 'on', 'last-generation', 'ipads'], ['Q2796', 'Q483551'], [\"apple's\", 'new', 'ipad', 'releases', 'bring', 'big', 'deals', 'on', 'last', \"year's\", 'models.']], 'N23144': ['health', 'weightloss', ['50', 'worst', 'habits', 'for', 'belly', 'fat'], ['Q193583'], ['these', 'seemingly', 'harmless', 'habits', 'are', 'holding', 'you', 'back', 'and', 'keeping', 'you', 'from', 'shedding', 'that', 'unwanted', 'belly', 'fat', 'for', 'good.']], 'N86255': ['health', 'medical', ['dispose', 'of', 'unwanted', 'prescription', 'drugs', 'during', 'the', 'dea', \"'s\", 'take', 'back', 'day'], ['Q622899'], []]}\n",
            "{'N88753': 1, 'N45436': 2, 'N23144': 3, 'N86255': 4}\n",
            "{'lifestyle': 1, 'news': 2, 'health': 3, 'sports': 4}\n",
            "{'lifestyleroyals': 1, 'newsscienceandtechnology': 2, 'weightloss': 3, 'medical': 4}\n",
            "58218\n",
            "54184\n",
            "(130380, 30)\n",
            "(130380, 50)\n",
            "(58219, 300)\n",
            "(54185, 300)\n"
          ]
        }
      ],
      "source": [
        "def print_partial(d):\n",
        "  print(dict(list(d.items())[0:4]))\n",
        "\n",
        "print_partial(news)\n",
        "print_partial(news_index)\n",
        "print_partial(category_dict)\n",
        "print_partial(subcategory_dict)\n",
        "\n",
        "print(len(word_dict))\n",
        "print(len(content_dict))\n",
        "\n",
        "print(news_title.shape)\n",
        "print(news_content.shape)\n",
        "\n",
        "print(title_word_embedding_matrix.shape)\n",
        "print(content_word_embedding_matrix.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train_session = read_train_clickhistory(news_index,data_root_path,'MINDlarge_train/behaviors.tsv')\n",
        "# dev_session = read_train_clickhistory(news_index,data_root_path,'MINDlarge_dev/behaviors.tsv')\n",
        "\n",
        "# train_user = parse_user(news_index,train_session)\n",
        "# dev_user = parse_user(news_index,dev_session)\n",
        "\n",
        "# train_sess, train_user_id, train_label = get_train_input(news_index,train_session)\n",
        "# dev_sess, dev_user_id, dev_label = get_train_input(news_index,dev_session)"
      ],
      "metadata": {
        "id": "tMponzcoSeli"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get test session\n",
        "test_session = read_test_clickhistory_noclk(news_index,data_root_path,'MINDlarge_test/behaviors.tsv')\n",
        "print(test_session[0:1])\n",
        "# same as train_session, but no not-clicks\n",
        "test_user = parse_user(news_index,test_session)\n",
        "# same as train_user\n",
        "test_impressions, test_userids = get_test_input(news_index,test_session)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsyFpFDyVcw2",
        "outputId": "ceef99d9-5fca-41dc-bb2d-a19a65d99d75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['N121133', 'N104200', 'N43255', 'N55860', 'N128965', 'N38014', 'N89445', 'N66089', 'N90367', 'N1128', 'N117219', 'N65119', 'N116090', 'N116464', 'N49705', 'N122682', 'N748', 'N62415', 'N49511', 'N63918', 'N90367', 'N560', 'N34058', 'N122682', 'N66666', 'N109962', 'N6958', 'N63174', 'N108801', 'N110976', 'N118629', 'N31390', 'N42718', 'N82405', 'N16941', 'N47739', 'N53474', 'N18190'], ['N101071', 'N15647', 'N83400', 'N124838', 'N57092', 'N64623', 'N62785', 'N112133', 'N98744', 'N55764', 'N16531', 'N54103', 'N128905', 'N2296', 'N45689', 'N87027'], []]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H6IbtWLhy-ra"
      },
      "outputs": [],
      "source": [
        "# # Save preprocessing data as csv\n",
        "# import pandas as pd\n",
        "# import json\n",
        "\n",
        "# def get_paths(folder):\n",
        "#   train_session_path = os.path.join(project_path, '_data_', folder, 'train_session.csv')\n",
        "#   train_user_path = os.path.join(project_path, '_data_', folder, 'train_user_id.csv')\n",
        "#   train_label_path = os.path.join(project_path, '_data_', folder,  'train_label.csv')\n",
        "#   train_click_path = os.path.join(project_path, '_data_',folder,  'train_clicks.csv')\n",
        "#   train_meta_path = os.path.join(project_path, '_data_', folder, 'train-meta.json')\n",
        "\n",
        "#   dev_session_path = os.path.join(project_path, '_data_', folder, 'dev_session.csv')\n",
        "#   dev_user_path = os.path.join(project_path, '_data_', folder, 'dev_user_id.csv')\n",
        "#   dev_label_path = os.path.join(project_path, '_data_', folder, 'dev_label.csv')\n",
        "#   dev_click_path = os.path.join(project_path, '_data_', folder, 'dev_clicks.csv')\n",
        "#   dev_meta_path = os.path.join(project_path, '_data_', folder, 'dev-meta.json')\n",
        "#   return train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path\n",
        "\n",
        "# def save_processed_data_as_csv(folder):\n",
        "#   train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path = get_paths(folder)\n",
        "\n",
        "#   train_sess_df = pd.DataFrame(train_sess)\n",
        "#   train_sess_df.to_csv(train_session_path, index=False,header=False)\n",
        "\n",
        "#   train_user_id_df = pd.DataFrame(train_user_id)\n",
        "#   train_user_id_df.to_csv(train_user_path, index=False,header=False)\n",
        "\n",
        "#   train_label_df = pd.DataFrame(train_label)\n",
        "#   train_label_df.to_csv(train_label_path, index=False,header=False)\n",
        "\n",
        "#   dev_sess_df = pd.DataFrame(dev_sess)\n",
        "#   dev_sess_df.to_csv(dev_session_path, index=False,header=False)\n",
        "\n",
        "#   dev_user_id_df = pd.DataFrame(dev_user_id)\n",
        "#   dev_user_id_df.to_csv(dev_user_path, index=False,header=False)\n",
        "\n",
        "#   dev_label_df = pd.DataFrame(dev_label)\n",
        "#   dev_label_df.to_csv(dev_label_path, index=False,header=False)\n",
        "\n",
        "#   train_click_df = pd.DataFrame(train_user['click'][train_user_id])\n",
        "#   train_click_df.to_csv(train_click_path, index=False,header=False)\n",
        "\n",
        "#   dev_click_df = pd.DataFrame(dev_user['click'][dev_user_id])\n",
        "#   dev_click_df.to_csv(dev_click_path, index=False,header=False)\n",
        "\n",
        "\n",
        "#   with open(train_meta_path, 'w') as f:\n",
        "#     json.dump({ \"impressionNum\": train_label.shape[0] }, f)\n",
        "\n",
        "#   with open(dev_meta_path, 'w') as f:\n",
        "#     json.dump({ \"impressionNum\": dev_label.shape[0] }, f)\n",
        "\n",
        "#   # return train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path\n",
        "# train_session_path, train_user_path, train_label_path, train_click_path, train_meta_path, dev_session_path, dev_user_path, dev_label_path, dev_click_path, dev_meta_path = get_paths('_small-processed_')\n",
        "# # save_processed_data_as_csv('_small-processed_')\n",
        "# # save_processed_data_as_csv('_processed_')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F5lX0VHbzHb5"
      },
      "outputs": [],
      "source": [
        "from Generator import NewsFetcher\n",
        "news_fetcher = NewsFetcher(news_title,news_content,news_vert,news_subvert,news_entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-DP2x4bqzIUU"
      },
      "outputs": [],
      "source": [
        "# train_generator = get_train_generator_2(news_fetcher,train_user['click'],train_user_id,train_sess,train_label,64)\n",
        "# val_generator = get_train_generator_2(news_fetcher,dev_user['click'], dev_user_id, dev_sess, dev_label, 64)\n",
        "news_generator = get_hir_news_generator(news_fetcher,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZyIRNjBLzMGQ"
      },
      "outputs": [],
      "source": [
        "# print(len(train_generator))\n",
        "# print(len(val_generator))\n",
        "# # print(train_generator.label_reader.loc[100:120].compute().values)\n",
        "\n",
        "# res = val_generator[2000]\n",
        "\n",
        "# print(res[0][0].shape, res[0][1].shape, res[1].shape)\n",
        "\n",
        "# train_generator[i] return i-th batch with format ((news_info, user_info), [labels])\n",
        "\n",
        "# news_info.shape = (batch_size, train_sess.shape[1]=npratio+1, 87) -> represent the current clicked news and 4 not-clicked news\n",
        "# user_info.shape = (batch_size, 50, 87) -> represent the clicked news before the current clicked news\n",
        "# labels.shape = (batch_size, 5) -> 1 for clicked news, 0 for not-clicked news matched with news_info -> (1, 0, 0, 0, 0)\n",
        "\n",
        "# test code\n",
        "# gen_news_data, gen_labels = train_generator[0]\n",
        "# gen_news_info, gen_user_info = gen_news_data\n",
        "\n",
        "# print(gen_news_info.shape)\n",
        "# print(gen_user_info.shape)\n",
        "# print(gen_labels[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uhYFSoTyzOcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cba9f6-8f04-4980-8cf7-f7d98dc8b96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)       [(None, 30, 87)]             0         []                            \n",
            "                                                                                                  \n",
            " input_15 (InputLayer)       [(None, 5, 87)]              0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 30, 400)              4365399   ['input_14[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDi  (None, 5, 400)               4365399   ['input_15[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " model_8 (Functional)        (None, 370)                  708771    ['time_distributed_1[0][0]']  \n",
            "                                                                                                  \n",
            " model_12 (Functional)       (None, 30)                   1769519   ['input_14[0][0]']            \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 5, 400)               0         ['time_distributed_2[0][0]']  \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 400)                  0         ['model_8[0][0]',             \n",
            " )                                                                   'model_12[0][0]']            \n",
            "                                                                                                  \n",
            " dot_6 (Dot)                 (None, 5)                    0         ['dropout_19[0][0]',          \n",
            "                                                                     'concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " recommend (Activation)      (None, 5)                    0         ['dot_6[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62057954 (236.73 MB)\n",
            "Trainable params: 62057954 (236.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "news_encoder\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 87)]                 0         []                            \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 1)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 1)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 1, 128)               2432      ['lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)     (None, 1, 128)               37632     ['lambda_2[0][0]']            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 128)                  0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 128)                  0         ['embedding_4[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 30)                   0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)           (None, 50)                   0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  16512     ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  16512     ['reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " lambda_4 (Lambda)           (None, 5)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, 400)                  1790610   ['lambda[0][0]']              \n",
            "                                                          1                                       \n",
            "                                                                                                  \n",
            " model_3 (Functional)        (None, 400)                  1669590   ['lambda_3[0][0]']            \n",
            "                                                          1                                       \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 128)                  0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 128)                  0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " model_5 (Functional)        (None, 200)                  8476101   ['lambda_4[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 1256)                 0         ['model_1[0][0]',             \n",
            "                                                                     'model_3[0][0]',             \n",
            "                                                                     'dropout_9[0][0]',           \n",
            "                                                                     'dropout_10[0][0]',          \n",
            "                                                                     'model_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 400)                  502800    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 43653991 (166.53 MB)\n",
            "Trainable params: 43653991 (166.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "user_encoder\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)       [(None, 30, 87)]             0         []                            \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 30, 400)              4365399   ['input_14[0][0]']            \n",
            " stributed)                                               1                                       \n",
            "                                                                                                  \n",
            " model_8 (Functional)        (None, 370)                  708771    ['time_distributed_1[0][0]']  \n",
            "                                                                                                  \n",
            " model_12 (Functional)       (None, 30)                   1769519   ['input_14[0][0]']            \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 400)                  0         ['model_8[0][0]',             \n",
            " )                                                                   'model_12[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62057954 (236.73 MB)\n",
            "Trainable params: 62057954 (236.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "model,news_encoder,user_encoder, = create_model(title_word_embedding_matrix,content_word_embedding_matrix,entity_dict,category_dict,subcategory_dict)\n",
        "\n",
        "print(\"model\")\n",
        "model.summary()\n",
        "print(\"news_encoder\")\n",
        "news_encoder.summary()\n",
        "print(\"user_encoder\")\n",
        "user_encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vrMDZEQ1zwCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feed337a-d7a3-4852-8eee-57b9a73a204c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load weights from /content/gdrive/MyDrive/Dataset/MIND/_checkpoints_/cp.ckpt\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_dir = os.path.join(project_path, '_checkpoints_')\n",
        "checkpoint_path = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "latest_weight = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "if latest_weight:\n",
        "    model.load_weights(latest_weight)\n",
        "    print(\"load weights from {}\".format(latest_weight))\n",
        "else:\n",
        "    print(\"no weights found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_scoring = news_encoder.predict_generator(news_generator,verbose=1)\n",
        "test_user_generator = get_hir_user_generator(news_fetcher,test_user['click'],64)\n",
        "test_user_scoring = user_encoder.predict_generator(test_user_generator,verbose=1)\n",
        "dump_result(test_impressions,news_scoring,test_user_scoring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDANKqB3AocJ",
        "outputId": "dc69d473-7431-4e77-8552-326006f85635"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-0120a42a4809>:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  news_scoring = news_encoder.predict_generator(news_generator,verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2038/2038 [==============================] - 11s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-0120a42a4809>:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  test_user_scoring = user_encoder.predict_generator(test_user_generator,verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74086/74086 [==============================] - 4381s 59ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp prediction.txt /content/gdrive/MyDrive/Dataset/MIND/"
      ],
      "metadata": {
        "id": "uUhKNG3H63XA"
      },
      "execution_count": 21,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNr9yBRRrO/TaqOZiPf7nD1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}